View(data.trimmed)
set.seed(666) #seed
library(ggplot2)
library(scales)
library(class)
library(e1071)
library(randomForest)
library(reshape2)
library(ggplot2)
library(scales)
library(class)
library(e1071)
library(randomForest)
library(reshape2)
N <- nrow(data.trimmed) #Determine data length
train.pct <- .7 #Set training set to 70%
train.data[1,]
train.data[1,15:20]
train.data[1,21:25]
train.data[1,25:28]
train.data[1,25:27]
data.trimmed[1,25:27]
data.trimmed[1,28:31]
data.trimmed[1,28:30]
data.trimmed[1,c(28:30,40:41)]
simple.data <- data.trimmed[,c(28:30,40:41)]
N <- nrow(simple.data) #Determine data length
train.pct <- .7 #Set training set to 70%
for (i in 1:4) {
xval <- i
train.index <- sample(1:N, train.pct * N)       # Create a random sample of records from the training set
train.data <- simple.data[train.index,]       # Split training data using random indexs derived from sampling
test.data <- simple.data[-train.index,]       # Split test data
#Separate labels from data
x.train <- train.data[,-(4:5)]
y.train <- train.data[,5]
x.test <- test.data[,-(4:5)]
y.test <- test.data[,5]
#run nb and save model and confusion matrix in tagged variable
nb.classifier <- naiveBayes(x.train, y.train)
nb.prediction <- predict(nb.classifier, x.test)
assign(paste("nb.performance.matrix.xval.", xval, sep=""),table(nb.prediction,y.test))
assign(paste("nb.classifier.xval.", xval, sep=""),nb.classifier)
assign(paste("nb.prediction.xval.", xval, sep=""),nb.prediction)
}
fix(nb.performance.matrix.xval.1)
getwd()
write.csv(nb.performance.matrix.xval.1,'~/Desktop/nb.performance.matrix.xval.1.csv')
write.csv(nb.performance.matrix.xval.2,'~/Desktop/nb.performance.matrix.xval.2.csv')
write.csv(nb.performance.matrix.xval.3,'~/Desktop/nb.performance.matrix.xval.3.csv')
write.csv(nb.performance.matrix.xval.4,'~/Desktop/nb.performance.matrix.xval.4.csv')
summary(nb.classifier)
nb.classifier
nb.prediction
fix(nb.classifier.xval.1)
nb.classifier.xval.1
summary(nb.classifier.xval.1)
str(nb.classifier.xval.1)
summary(nb.prediction.xval.1)
data.trimmed[1,40:41]
summary(data.trimmed[,41])
data.trimmed[1,1:10]
summary(data.trimmed[,3])
summary(data.trimmed[,4])
data.trimmed[1,11:20]
data.trimmed[1,21:30]
data.trimmed[1,22:30]
data.trimmed[1,22:27]
summary(data.trimmed[,22:27])
data.trimmed[1,15:20]
data.trimmed[1,13:20]
data.trimmed[1,12:20]
data.trimmed[1,13:22]
data.trimmed[1,13:21]
summary(data.trimmed[1,13:21])
summary(data.trimmed[,13:21])
data.trimmed[1,1:21]
data.trimmed[1,21:31]
data.trimmed[1,6:21]
data.trimmed[1,10:21]
data.trimmed[1,9:21]
data.trimmed[1,10:13]
summary(data.trimmed[,10:12])
summary(data.trimmed[,3:10])
summary(data.trimmed[,5:10])
summary(data.trimmed[,6:7])
summary(data.trimmed[,5])
summary(data.trimmed[,5:6])
summary(data.trimmed[,8:9])
library(ggplot2)
library(scales)
library(class)
library(e1071)
library(randomForest)
library(reshape2)
library(ggplot2)
library(scales)
library(class)
library(e1071)
library(randomForest)
library(reshape2)
data.trimmed[1,4:41]
data.trimmed[1,c(10:41)]
data.trimmed[1,c(15:41)]
data.trimmed[1,c(50:41)]
data.trimmed[1,c(20:41)]
data.trimmed[1,c(25:41)]
data.trimmed[1,c(27:41)]
data.trimmed[1,c(28:41)]
data.trimmed[1,c(28:31,40:41)]
data.trimmed[1,c(28:32,40:41)]
data.trimmed[1,c(28:31,40:41)]
data.trimmed[1,c(28:30,40:41)]
data.trimmed[1,c(28:30,39:41)]
simple.data <- data.trimmed[1,c(28:30,40:41)]
N <- nrow(data.trimmed) #Determine data length
train.pct <- .7 #Set training set to 70%
simple.data <- data.trimmed[,c(28:30,40:41)]
simple.data[1,]
train.index <- sample(1:N, train.pct * N)       # Create a random sample of records from the training set
train.data <- simple.data[train.index,]       # Split training data using random indexs derived from sampling
test.data <- simple.data[-train.index,]
x.train <- train.data[,-(4:5)]
y.train <- train.data[,4:5]
x.test <- test.data[,-(4:5)]
y.test <- test.data[,4:5]
y.test[1,]
rf.classifier.dummy <- randomForest(x.train[,1:3], y.train[,1], ntree=100,keep.forest=TRUE,importance=TRUE)
rf.classifier.battles <- randomForest(x.train[,1:3], y.train[,2], ntree=100,keep.forest=TRUE,importance=TRUE)
#Output forrests
sink(file="~/Desktop/classifiers.txt")
"dummy"
rf.classifier.dummy
"--------------------------------------"
""
""
""
"battles"
rf.classifier.battles
sink(NULL)
#Plot forest performance
#dummy
dummy.rf.perf <- data.frame(cbind(1:100,plot(rf.classifier.dummy)))
colnames(dummy.rf.perf) <- c('Trees', 'OOB', 'No battles', 'Battles')
dummy.rf.perf <- melt(dummy.rf.perf,id='Trees')
p.dummy.rf.perf <- ggplot(dummy.rf.perf,aes(x=Trees,y=value)) + geom_line(aes(colour = variable)) + theme_bw() + labs(title = 'Performance of Random Forrest on binary classification',x='Number of trees',y='Error')
ggsave(p.dummy.rf.perf,file='~/Desktop/dummy_rf_performance.png',height=8.5,width=11)
#battles
battles.rf.perf <- data.frame(cbind(1:100,plot(rf.classifier.battles)))
colnames(battles.rf.perf) <- c('Trees', 'Performance')
p.battles.rf.perf <- ggplot(battles.rf.perf,aes(x=Trees,y=Performance)) + geom_line() + theme_bw() + labs(title = 'Performance of Random Forrest on regression classification',x='Number of trees',y='Error')
ggsave(p.battles.rf.perf,file='~/Desktop/battles_rf_performance.png',height=8.5,width=11)
#TEST
test.data$pred.dummy.rf = predict(rf.classifier.dummy, test.data, type='response')
test.data$pred.battles.rf = predict(rf.classifier.battles, test.data, type='response')
#Confusion matrix for dummy target
rf.dummy.confusion.matrix <- table(y.test[,2],test.data$pred.dummy.rf)
rf.dummy.perf.table <- prop.table(table(y.test[,2], test.data$pred.dummy.rf),1)
write.csv(rf.dummy.confusion.matrix,'~/Desktop/rf.dummy.confusion.matrix.csv')
write.csv(rf.dummy.perf.table,'~/Desktop/rf.dummy.perf.table.csv')
#varialbe importance
sink(file="~/Desktop/varible_importance.txt")
"dummy"
importance(rf.classifier.dummy)
"--------------------------------------"
""
""
""
"battles"
importance(rf.classifier.battles)
sink(NULL)
varImpPlot(rf.classifier.dummy)
varImpPlot(rf.classifier.battles)
View(districts)
rr.classifier.dummy
rf.classifier.dummy
p.dummy.rf.perf
dummy.rf.perf <- data.frame(cbind(1:100,plot(rf.classifier.dummy)))
colnames(dummy.rf.perf) <- c('Trees', 'OOB', 'No battles', 'Battles')
dummy.rf.perf
dummy.rf.perf <- data.frame(cbind(1:100,plot(rf.classifier.dummy)))
dummy.rf.perf
plot(rf.classifier.dummy)
summary(plot(rf.classifier.dummy))
str(plot(rf.classifier.dummy))
rf.classifier.dummy
rf.classifier.battle
rf.classifier.battles
dummy.rf.perf <- data.frame(cbind(1:100,plot(rf.classifier.battles)))
colnames(dummy.rf.perf) <- c('Trees', 'OOB', 'No battles', 'Battles')
dummy.rf.perf <- melt(dummy.rf.perf,id='Trees')
p.dummy.rf.perf <- ggplot(dummy.rf.perf,aes(x=Trees,y=value)) + geom_line(aes(colour = variable)) + theme_bw() + labs(title = 'Performance of Random Forrest on binary classification',x='Number of trees',y='Error')
ggsave(p.dummy.rf.perf,file='~/Desktop/dummy_rf_performance.png',height=8.5,width=11)
#battles
battles.rf.perf <- data.frame(cbind(1:100,plot(rf.classifier.dummy)))
colnames(battles.rf.perf) <- c('Trees', 'Performance')
p.battles.rf.perf <- ggplot(battles.rf.perf,aes(x=Trees,y=Performance)) + geom_line() + theme_bw() + labs(title = 'Performance of Random Forrest on regression classification',x='Number of trees',y='Error')
ggsave(p.battles.rf.perf,file='~/Desktop/battles_rf_performance.png',height=8.5,width=11)
#Confusion matrix for dummy target
rf.dummy.confusion.matrix <- table(y.test[,2],test.data$pred.dummy.rf)
rf.dummy.perf.table <- prop.table(table(y.test[,2], test.data$pred.dummy.rf),1)
write.csv(rf.dummy.confusion.matrix,'~/Desktop/rf.dummy.confusion.matrix.csv')
write.csv(rf.dummy.perf.table,'~/Desktop/rf.dummy.perf.table.csv')
rf.dummy.confusion.matrix <- table(y.test[,2],test.data$pred.dummy.rf)
rf.dummy.confusion.matrix
#TEST
test.data$pred.dummy.rf = predict(rf.classifier.battles, x.test, type='response')
test.data$pred.battles.rf = predict(rf.classifier.dummy, x.test, type='response')
test.data$pred.dummy.rf
#TEST
test.data$pred.dummy.rf = predict(rf.classifier.battles, test.data[,-(4:5)], type='response')
test.data$pred.battles.rf = predict(rf.classifier.dummy, test.data[,-(4:5)], type='response')
rf.dummy.confusion.matrix <- table(y.test[,2],test.data$pred.dummy.rf)
rf.dummy.perf.table <- prop.table(table(y.test[,2], test.data$pred.dummy.rf),1)
write.csv(rf.dummy.confusion.matrix,'~/Desktop/rf.dummy.confusion.matrix.csv')
write.csv(rf.dummy.perf.table,'~/Desktop/rf.dummy.perf.table.csv')
